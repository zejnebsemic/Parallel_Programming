# ParallelComputing
I ran the BabelStream benchmarks for different programming models as per the assignment. First, I compiled and ran the OpenMP version on my local CPU. I tested it with 1, 2, 4, and 8 threads by setting OMP_NUM_THREADS. The program ran successfully each time. The bandwidth results were around 6,000–6,200 MB/s for simple operations like Copy and Mul, and up to about 9,400 MB/s for the Dot product. Performance scaled up to 4 threads, but adding more threads didn’t help much because the CPU’s memory bandwidth became the limit—this is normal for memory-bound tasks on a CPU. 

Then I tried the OpenCL version on the iGPU. It compiled, but when I ran it, it crashed immediately with a clGetPlatformIDs error, which means OpenCL couldn’t find a usable platform, likely because the drivers or runtime for the integrated graphics weren’t installed or set up correctly. So I got no results from the iGPU. 

For the GPU part, I connected to the lab server via SSH and tried to run the CUDA version. The program started but then quit without printing any benchmark results. It probably failed silently because the GPU didn’t have enough memory for the 805 MB total array size, or there was some CUDA setup issue. 
Comparing CPU and GPU: the CPU gave solid, expected results. A real GPU should be much faster—like 5 to 10 times—because GPUs have faster memory (like GDDR) and can do thousands of operations at once. But in my case, neither the iGPU nor the server GPU worked due to setup problems: missing OpenCL platform for the iGPU and likely out-of-memory or configuration issues for the CUDA GPU. So the assignment showed me that in practice, getting GPU code to run involves more than just the code—it needs proper drivers, enough memory, and correct system setup. All the steps and results are captured in the screenshots I took: pic1 shows OpenMP compilation, pic2 and pic3 show OpenMP runs with different thread counts, pic4 has formatted results, pic5 shows the OpenCL error and pic6 shows the silent CUDA failure.

